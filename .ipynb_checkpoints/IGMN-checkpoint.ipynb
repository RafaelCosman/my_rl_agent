{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-06-05 20:58:51,763] Making new env: Acrobot-v0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'IGMN'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-4fcc3e782536>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[0mamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhigh\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m \u001b[0mig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0migmn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIGMN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'IGMN'"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Federal University of Rio Grande do Sul (UFRGS)\n",
    "# Connectionist Artificial Intelligence Laboratory (LIAC)\n",
    "# Renato de Pontes Pereira - rppereira@inf.ufrgs.br\n",
    "# =============================================================================\n",
    "# Copyright (c) 2011 Renato de Pontes Pereira, renato.ppontes at gmail dot com\n",
    "# \n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy \n",
    "# of this software and associated documentation files (the \"Software\"), to deal \n",
    "# in the Software without restriction, including without limitation the rights \n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell \n",
    "# copies of the Software, and to permit persons to whom the Software is \n",
    "# furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in \n",
    "# all copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR \n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, \n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE \n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER \n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, \n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE \n",
    "# SOFTWARE.\n",
    "# =============================================================================\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.linalg\n",
    "import sklearn\n",
    "import math\n",
    "from numba import jit\n",
    "\n",
    "__all__ = ['IGMN']\n",
    "\n",
    "EPS = np.finfo(float).eps\n",
    "TINY = np.finfo(float).tiny\n",
    "\n",
    "def mvnpdf(x, mu=None, sigma=None):\n",
    "    '''Multivariate normal probability density function (pdf).'''\n",
    "\n",
    "    dimension = len(x)\n",
    "\n",
    "    if mu is None:\n",
    "        mu = np.zeros(dimension)\n",
    "\n",
    "    if sigma is None:\n",
    "        sigma = np.eye(dimension)\n",
    "\n",
    "    distance = x-mu\n",
    "    determinant = np.linalg.det(sigma)\n",
    "    inverse = np.linalg.inv(sigma)\n",
    "\n",
    "    return np.exp(-0.5*(distance).dot(inverse).dot(distance)) * \\\n",
    "           1.0/((2*np.pi)**(dimension/2.0) * np.sqrt(determinant))\n",
    "\n",
    "\n",
    "class IGMN(sklearn.base.BaseEstimator):\n",
    "    '''\n",
    "    The class for IGMN (Incremental Gaussian Mixture Network).\n",
    "    .. NOTE: By convention the word \"component\" is used instead of \"neuron\".\n",
    "    '''\n",
    "\n",
    "    def __init__(self, distance=None, delta=0.1, tau=0.1, sp_min=None, \n",
    "                       v_min=None, tau_max=None, uniform=False):\n",
    "        '''\n",
    "        Creates a new IGMN instance. \n",
    "        The `distance` is the only mandatory parameter in this method. This \n",
    "        parameter represents the data range, i.e., ``max(data)-min(data)``;. \n",
    "        You can get the data range automatically using `liac.data_range`.\n",
    "        The `delta` parameter is a fraction of the `distance` which will be \n",
    "        used to create the initial covariance matrices. In a practical view, \n",
    "        this parameter defines the size of the distributions.\n",
    "        The `tau` and `tau_max` are thresholds which inform IGMN when to create\n",
    "        and update the components, respectively. When a new input pattern is \n",
    "        presented to this model, the likelihood relative to the input and all\n",
    "        components is computed. A given component can \"absorbs\" the input if it\n",
    "        represents well enough the pattern, i.e., if its likelihood is greater \n",
    "        than `tau`. The `tau_max` is used to avoid over-fitting, restraining \n",
    "        the update for components when the likelihood is too big (e.g., >0.95).\n",
    "        The `sp_min` and `v_min` parameters are used to remove noisy \n",
    "        components. When a new input pattern is presented to the model, it \n",
    "        verifies if some component is older than `v_min` and have less \n",
    "        activation than `sp_min`, if it is the case, the component is removed.\n",
    "        The `uniform` parameter defines is the components are equiprobable or \n",
    "        not. I.e., if ``uniform = True``, all components will have the same \n",
    "        prior probability.\n",
    "        :param distance: an 1xD numpy array.\n",
    "        :param delta: an float between 0 and 1. Default to 0.1.\n",
    "        :param tau: an float between 0 and 1. Default to 0.1.\n",
    "        :param sp_min: a real number. Default to D+1.\n",
    "        :param v_min: an integer. Default to D*2.\n",
    "        :param tau_max: an float between 0 and 1, must be bigger than `tau`. \n",
    "                        Default to None.\n",
    "        :param uniform: a boolean. Default to False.\n",
    "        '''\n",
    "        self.distance = distance\n",
    "        self.dimension = distance.size\n",
    "        self.size = 0\n",
    "        self.n = 0\n",
    "        \n",
    "        self.priors = []\n",
    "        self.means = []\n",
    "        self.covs = []\n",
    "        self.sps = []\n",
    "        self.vs = []\n",
    "        self.posts = []\n",
    "        self.log_likes = []\n",
    "        self.nlikes = []\n",
    "        self.log_posts = []\n",
    "        \n",
    "        # CACHE ===============================================================\n",
    "        self.cache_inverses = []\n",
    "        self.cache_dets = []\n",
    "        self.cache_distances = []\n",
    "        self.cache_like = []\n",
    "        # =====================================================================\n",
    "\n",
    "        # PARAMS ==============================================================\n",
    "        self.tau_max = tau_max\n",
    "        self.delta = delta\n",
    "        self.tau = tau\n",
    "        self.sp_min = sp_min #if sp_min is not None else self.dimension+1\n",
    "        self.v_min = v_min #if v_min is not None else 2*self.dimension\n",
    "        self.initial_cov = np.diagflat((self.delta*self.distance)**2)\n",
    "        self.min_cov = np.eye(self.dimension)*EPS\n",
    "        self.uniform = uniform\n",
    "        self.lrs = None\n",
    "        # =====================================================================\n",
    "\n",
    "        # EXPERIMENTAL ========================================================\n",
    "        self.able_to_updates = []\n",
    "        # =====================================================================\n",
    "\n",
    "    # INTERNAL METHODS ========================================================\n",
    "    #@jit\n",
    "    def log_mvnpdf(self, X, i):\n",
    "        mu = self.means[i]\n",
    "        cov = self.covs[i]\n",
    "\n",
    "        idx = np.where(~np.isnan(X))[0]\n",
    "        #n_dim = X.size\n",
    "        n_dim = idx.size\n",
    "        cv_chol = scipy.linalg.cholesky(cov[np.ix_(idx,idx)], lower=True)\n",
    "        cv_log_det = 2 * np.sum(np.log(np.diagonal(cv_chol)))\n",
    "        cv_sol = scipy.linalg.solve_triangular(cv_chol, (X[idx] - mu[idx]).T, lower=True).T\n",
    "        log_prob = -.5*(np.sum(cv_sol**2) + n_dim*np.log(2*np.pi) + cv_log_det)\n",
    "        self.nlikes[i] = math.exp(-.5*np.sum(cv_sol**2))\n",
    "        self.cache_like[i] = -.5*np.sum(cv_sol**2)\n",
    "\n",
    "        return log_prob\n",
    "\n",
    "    def __mvnpdf(self, x, mean, cov):\n",
    "        pdf = mvnpdf(x, mean, cov)\n",
    "\n",
    "        if np.isnan(pdf): \n",
    "            pdf = 0\n",
    "        \n",
    "        return pdf + TINY\n",
    "\n",
    "    def __pdf(self, x, i):\n",
    "        dimension = self.dimension\n",
    "        mu = self.means[i]\n",
    "        cov = self.covs[i]\n",
    "\n",
    "        if self.cache_inverses[i] is None:\n",
    "            self.cache_inverses[i] = np.linalg.inv(cov)\n",
    "\n",
    "        if self.cache_dets[i] is None:\n",
    "            self.cache_dets[i] = np.linalg.det(cov)\n",
    "            \n",
    "        distance = x-mu\n",
    "        inverse = self.cache_inverses[i]\n",
    "        determinant = self.cache_dets[i]\n",
    "\n",
    "        density = ((2*np.pi)**(dimension/2.0) * np.sqrt(determinant))\n",
    "        self.cache_distances[i] = np.exp(-0.5*(distance).dot(inverse).dot(distance))\n",
    "        pdf = self.cache_distances[i]/density\n",
    "\n",
    "        if np.isnan(pdf): \n",
    "            pdf = 0\n",
    "        \n",
    "        return pdf + TINY\n",
    "\n",
    "    def __get_index_by_features(self, features_a, features_b=None):\n",
    "        if features_b is None: features_b = features_a\n",
    "        return [[i*self.dimension+j for j in features_b] for i in features_a]\n",
    "\n",
    "    def _compute_likelihood(self, x):\n",
    "        self.log_likes = []\n",
    "        self.nlikes = np.zeros((self.size))\n",
    "        self.cache_like = np.zeros(self.size)\n",
    "        for i in range(self.size):\n",
    "            self.log_likes.append(self.log_mvnpdf(x, i))\n",
    "\n",
    "    def _compute_posterior(self):\n",
    "        log_density = np.exp(self.log_likes + np.log(self.priors))\n",
    "        self.posts = log_density/np.sum(log_density)\n",
    "\n",
    "\n",
    "    def _has_acceptable_distribution(self):\n",
    "        if not self.size:\n",
    "            return False\n",
    "\n",
    "        r = False\n",
    "        min_like = np.log(self.tau)\n",
    "        \n",
    "        if self.tau_max is not None:\n",
    "            max_like = np.log(self.tau_max)\n",
    "\n",
    "        for i in range(self.size):\n",
    "            if self.cache_like[i] >= min_like:\n",
    "                r = True\n",
    "\n",
    "                if self.tau_max is not None:\n",
    "                    if self.cache_like[i] > max_like:\n",
    "                        self.able_to_updates[i] = False\n",
    "                    else:\n",
    "                        self.able_to_updates[i] = True\n",
    "                else:\n",
    "                    self.able_to_updates[i] = True\n",
    "        return r\n",
    "\n",
    "    def _incremental_estimation(self, x):\n",
    "        idx = np.where(np.isnan(x))[0]\n",
    "        for i in range(self.size):\n",
    "            if not self.able_to_updates[i] or self.posts[i] < 1.0 / (self.size+1): continue\n",
    "            x_ = x.copy()\n",
    "            x_[idx] = self.means[i][idx]\n",
    "            self.vs[i] += 1\n",
    "            self.sps[i] += self.posts[i]\n",
    "\n",
    "            w = self.posts[i] / self.sps[i]\n",
    "            w = w_ = max(w, 1e-9)\n",
    "            #print(i, w)\n",
    "            if self.lrs is not None:\n",
    "                w = np.repeat(w, x.shape[0])\n",
    "                lr_idx = np.where(~np.isnan(self.lrs))[0]\n",
    "                w[lr_idx] = self.posts[i] * self.lrs[lr_idx]\n",
    "                w_ = np.sqrt(np.outer(w,w))\n",
    "                w_[lr_idx,:] = self.posts[i] * np.atleast_2d(self.lrs[lr_idx]).T\n",
    "                w_[:,lr_idx] = self.posts[i] * np.atleast_2d(self.lrs[lr_idx])\n",
    "                #print(w)\n",
    "                #print(w_)\n",
    "                #w = w[idx]\n",
    "                #w_ = w_[np.ix_(idx,idx)]\n",
    "                #w_[-1,-1] = 0\n",
    "            #print(w_)\n",
    "            #wi = 1-w\n",
    "            wi_ = 1-w_\n",
    "\n",
    "            old_mean = self.means[i]\n",
    "            old_cov = self.covs[i]\n",
    "            delta = w*(x_ - old_mean);\n",
    "            new_mean = old_mean + delta\n",
    "            \n",
    "            diff = x_ - new_mean\n",
    "            new_cov = wi_*old_cov - np.outer(delta, delta) + w_*np.outer(diff, diff) + self.min_cov\n",
    "            #new_cov[-1,-1] = old_cov[-1,-1]\n",
    "            if np.linalg.det(new_cov) > 0:\n",
    "                self.means[i] = new_mean\n",
    "                self.covs[i] = new_cov\n",
    "                self.cache_inverses[i] = None\n",
    "                self.cache_dets[i] = None\n",
    "                self.cache_distances[i] = None\n",
    "            else:\n",
    "                print(\"Invalid covariance matrix %d.\" % i)\n",
    "\n",
    "    def _update_priors(self):\n",
    "        if self.uniform:\n",
    "            self.priors = [1.0 / self.size] * self.size\n",
    "        else:\n",
    "            sp_sum = float(np.sum(self.sps))\n",
    "            self.priors = [self.sps[i]/sp_sum for i in range(self.size)]\n",
    "\n",
    "    def _delete_spurious(self):\n",
    "        for i in reversed(range(self.size)):\n",
    "            if self.vs[i] > self.v_min and self.sps[i] < self.sp_min:\n",
    "            #if self.vs[i] > np.mean(self.vs) and self.sps[i] < np.mean(self.sps):\n",
    "                #print(\"REMOVEU vmin: %f spmin: %f\" % (self.v_min, self.sp_min))\n",
    "                self.size -= 1\n",
    "                del self.vs[i]\n",
    "                del self.sps[i]\n",
    "                del self.priors[i]\n",
    "                del self.means[i]\n",
    "                del self.covs[i]\n",
    "                del self.cache_inverses[i]\n",
    "                del self.cache_dets[i]\n",
    "                del self.cache_distances[i]\n",
    "                del self.able_to_updates[i]\n",
    "\n",
    "    def _new_component(self, x, cov=None, default=0):\n",
    "        if cov is None:\n",
    "            cov = self.initial_cov.copy()\n",
    "            \n",
    "        self.size += 1\n",
    "        self.able_to_updates.append(True)\n",
    "        self.priors.append(1)\n",
    "        self.sps.append(1)\n",
    "        self._update_priors()\n",
    "        self.vs.append(1)\n",
    "        idx = np.where(np.isnan(x))[0]\n",
    "        x_ = x.copy()\n",
    "        x_[idx] = default   \n",
    "        self.means.append(x_)\n",
    "        self.covs.append(cov)\n",
    "        self.cache_inverses.append(None)\n",
    "        self.cache_dets.append(None)\n",
    "        self.cache_distances.append(None)\n",
    "    # =========================================================================\n",
    "\n",
    "    def reset(self):\n",
    "        '''\n",
    "        Reset the model, removing all components but keeping the parameters.\n",
    "        '''\n",
    "        self.n = 0\n",
    "        self.able_to_updates = []\n",
    "\n",
    "        self.size = 0\n",
    "        self.priors = []\n",
    "        self.means = []\n",
    "        self.covs = []\n",
    "        self.sps = []\n",
    "        self.vs = []\n",
    "        self.log_likes = []\n",
    "        self.nlikes = []\n",
    "        self.posts = []\n",
    "        self.cache_inverses = []\n",
    "        self.cache_dets = []\n",
    "        self.cache_densitys = []\n",
    "        self.cache_distances = []\n",
    "\n",
    "    def learn(self, x, default=0, searchIndices=None):\n",
    "        '''\n",
    "        Learns a single instance.\n",
    "        :param x: an 1xD numpy array.\n",
    "        :returns: a list with the posterior probabilities.\n",
    "        '''\n",
    "        if searchIndices is None:\n",
    "            searchIndices = range(x.shape[0])\n",
    "        self._compute_likelihood(x[searchIndices])\n",
    "        if not self._has_acceptable_distribution():\n",
    "            self._new_component(x, default=default)\n",
    "            self._compute_likelihood(x[searchIndices])\n",
    "            self._update_priors()\n",
    "            \n",
    "        self._compute_posterior()\n",
    "        self._incremental_estimation(x)\n",
    "        self._update_priors()\n",
    "        if self.v_min is not None and self.sp_min is not None:\n",
    "            self._delete_spurious()\n",
    "\n",
    "        self.n += 1\n",
    "        return self.posts\n",
    "\n",
    "    def train(self, x, y=None):\n",
    "        '''\n",
    "        Learns a list of instances.\n",
    "        If `y` is None, IGMN assume that the target values are concatenated to \n",
    "        the `x` vectors.\n",
    "        :param x: an NxD numpy array with the prediction vectors.\n",
    "        :param y: an NxD numpy array with the target vectors. \n",
    "        '''\n",
    "        if y is None:\n",
    "            for row in x:\n",
    "                self.learn(row)\n",
    "        else:\n",
    "            for row_x, row_y in zip(x, y):\n",
    "                self.learn(liac.concat(row_x, row_y))\n",
    "\n",
    "    def fit(self, X):\n",
    "        X = np.atleast_2d(X)\n",
    "        for x in X:\n",
    "            self.learn(x)\n",
    "\n",
    "    def call(self, x):\n",
    "        '''\n",
    "        Computes the likelihood and posterior probabilities for a given input.\n",
    "        :param x: an 1xD numpy array.\n",
    "        :returns: a list with the posterior probabilities.\n",
    "        '''\n",
    "        self._compute_likelihood(x)\n",
    "        self._compute_posterior()\n",
    "        return self.posts\n",
    "\n",
    "    def recall(self, x, features=None):\n",
    "        '''\n",
    "        Performs the Gaussian Mixture Regression for a given input.\n",
    "        This method returns an estimate for the missing values. The `x` \n",
    "        parameter defines the known values while the `features` defines which\n",
    "        attributes are know. Notice, if ``features is None``, IGMN assumes that\n",
    "        the firsts M attributes are known, where M is the dimension of `x`.\n",
    "        :param x: an 1xM numpy array.\n",
    "        :param features: a list of integers. Default to None.\n",
    "        :returns: a numpy array with the estimate for the missing values.\n",
    "        '''\n",
    "        features_a = list(features or range(x.size))\n",
    "        features_b = sorted(list(set(range(self.dimension)) - set(features_a)))\n",
    "        #print(features_a, features_b)\n",
    "\n",
    "        inv = np.linalg.inv\n",
    "        pjas = []\n",
    "        xs = []\n",
    "\n",
    "        for index in range(self.size):\n",
    "            mean_a = self.means[index].take(features_a)\n",
    "            mean_b = self.means[index].take(features_b)\n",
    "            cov_a = self.covs[index].take(self.__get_index_by_features(features_a))\n",
    "            cov_ab = self.covs[index].take(self.__get_index_by_features(features_a, features_b))\n",
    "            \n",
    "            pja_ = self.__mvnpdf(x, mean_a, cov_a)*self.priors[index]\n",
    "            x_ = mean_b + np.dot(cov_ab.T, np.dot(inv(cov_a), x-mean_a))\n",
    "\n",
    "            pjas.append(pja_)\n",
    "            xs.append(x_)\n",
    "\n",
    "        pjas = pjas/np.sum(pjas)\n",
    "        return np.dot(pjas, xs)\n",
    "\n",
    "    def classify(self, x):\n",
    "        '''\n",
    "        Classify a given input.\n",
    "        It returns a label-binarized vector where the predict class have value \n",
    "        1.\n",
    "        :param x: an 1xM numpy array.\n",
    "        :returns: an array label-binarized.\n",
    "        '''\n",
    "        y_ = self.recall(x).tolist()\n",
    "        i = y_.index(max(y_))\n",
    "        y = np.zeros(self.dimension - x.size)\n",
    "        y[i] = 1\n",
    "\n",
    "        return y\n",
    "\n",
    "    def get_best_component(self, x=None):\n",
    "        '''\n",
    "        Return the index of component with the largest likelihood.\n",
    "        :return: an integer.\n",
    "        '''\n",
    "        if x is not None:\n",
    "            self.call(x)\n",
    "            \n",
    "        return np.argmax(self.posts)\n",
    "\n",
    "    def report(self):\n",
    "        s = ''\n",
    "        s += '-------------\\n'\n",
    "        s += 'Model Details\\n'\n",
    "        s += '-------------\\n'\n",
    "        s += '\\n'\n",
    "        s += 'Incremental Gaussian Mixture Network (IGMN)\\n'\n",
    "        s += '\\n'\n",
    "        s += 'Instances: ' + str(self.n)\n",
    "        s += '\\n'\n",
    "        s += 'COMPONENT (%d)\\n'%self.size\n",
    "        # s += '\\n'\n",
    "        for i in range(self.size):\n",
    "            s +=  '%4d - p(j): %.4f\\n'%(i, self.priors[i])\n",
    "            s += '     - mean: %s\\n' % self.means[i]\n",
    "            s += '     - det: %s\\n' % np.linalg.det(self.covs[i])\n",
    "            s += '\\n'\n",
    "        s += '\\n'\n",
    "        return s\n",
    "\n",
    "    def plot(self, *args, **kwargs):\n",
    "        import liac\n",
    "        if self.dimension == 1:\n",
    "            for i in range(self.size):\n",
    "                mean = self.means[i]\n",
    "                var = self.covs[i]\n",
    "\n",
    "                sigma = np.sqrt(var)\n",
    "                x_min = args[0] if len(args) > 0 else mean-self.distance[0]\n",
    "                x_max = args[1] if len(args) > 1 else mean+self.distance[0]\n",
    "\n",
    "                X = np.linspace(x_min, x_max, 500)\n",
    "                Y = liac.normpdf(X, mean, sigma)[0]\n",
    "\n",
    "                Y = Y/np.max(Y)\n",
    "\n",
    "                liac.plot.plot(X, Y, color=liac.random.make_color(i))\n",
    "\n",
    "        elif self.dimension == 2:\n",
    "            nstd = args[0] if len(args) > 0 else 2\n",
    "            ax = liac.plot.gca()\n",
    "            for i in range(self.size):\n",
    "                ellipse = liac.plot.Gaussian(self.means[i], self.covs[i], nstd, color=liac.random.make_color(i), alpha=0.75)\n",
    "                ax.add_artist(ellipse)\n",
    "                x, y= self.means[i]\n",
    "                liac.plot.plot(x, y, 'x', markersize=14, markeredgewidth=2, color='k')\n",
    "                liac.plot.plot(x, y, 'x', markersize=12, markeredgewidth=2, color=liac.random.make_color(i))\n",
    "                # liac.plot.add_ellipse(self.means[i], self.covs[i])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '<IGMN:%d:%d>'%(self.size, self.n)\n",
    "    __str__ = __repr__\n",
    "    __call__ = call\n",
    "\n",
    "import gym, random, time, itertools, sys, math, igmn\n",
    "import numpy as np\n",
    "\n",
    "env = gym.make('Acrobot-v0')\n",
    "#env.monitor.start('C:\\\\igmnq-acrobot-experiment-1', force=True)\n",
    "\n",
    "#Config\n",
    "N_EPISODES = 400\n",
    "MAX_STEPS = env.spec.timestep_limit\n",
    "K = 0\n",
    "TRIALS = env.spec.trials\n",
    "REWARD_THRESHOLD = env.spec.reward_threshold\n",
    "\n",
    "#Metaparameters\n",
    "discount = 0.1\n",
    "initialQ = 0.0\n",
    "decay = 0.0\n",
    "\n",
    "#Functions\n",
    "def activate(observation):\n",
    "\tglobal ig, K, W\n",
    "\tassert observation.shape[0] == n_features\n",
    "\tinp_ =  (observation - env.observation_space.low) / amp #Normalize\n",
    "\tig.learn(inp_)\n",
    "\tif ig.size > K:\n",
    "\t\tK = ig.size\n",
    "\t\tW = np.concatenate((W, initialQ+np.zeros((n_actions)).reshape((n_actions,1))), axis=1)\n",
    "\tacts_ = ig.nlikes.copy()\n",
    "\treturn acts_\n",
    "\n",
    "def addBias(x):\n",
    "\treturn np.concatenate( ([1.0], x) )\n",
    "\n",
    "def updateHistory(r):\n",
    "\tglobal best\n",
    "\thistory.append(r)\n",
    "\tif len(history) > TRIALS:\n",
    "\t\thistory.pop(0)\n",
    "\t\tm = np.mean(history)\n",
    "\t\tif m > best:\n",
    "\t\t\tbest = m\n",
    "\t\t\treturn True\n",
    "\treturn False\n",
    "\n",
    "def learn(s, a, s_, r, done, trace, elapsed=1):\n",
    "\tglobal W\n",
    "\tassert s.shape[0] == n_features\n",
    "\tassert s_.shape[0] == n_features\n",
    "\tassert trace.shape[0] == K + 1\n",
    "\tacts_ = activate(s)\n",
    "\tif ig.size+1 > trace.shape[0]:\n",
    "\t\ttrace = np.concatenate((trace, [0.0]))\n",
    "\tinp = addBias(acts_)\t#Add bias\n",
    "\ttrace = inp + decay * discount * trace #Update traces\n",
    "\tQ = W.dot(inp)\t#Feed forward to linear output layer\n",
    "\tcurrQ = Q[a]\n",
    "\tacts_ = activate(s_)\n",
    "\tif ig.size+1 > trace.shape[0]:\n",
    "\t\ttrace = np.concatenate((trace, [0.0]))\n",
    "\tnewInp = addBias(acts_)\n",
    "\tif done:\t#Last step\n",
    "\t\ttarget = reward\n",
    "\telse:\n",
    "\t\tnextQ = W.dot(newInp)\n",
    "\t\tmaxQ = nextQ.max()\n",
    "\t\ttarget = (1 - math.exp(-discount * elapsed)) / discount * r + math.exp(-discount * elapsed) * maxQ\n",
    "\ttd_error = target - currQ\n",
    "\t#print(ig.size, trace.shape, W[a,:].shape)\n",
    "\tdelta = lr * td_error * trace\n",
    "\tW[a,:] += delta #Update output layer for last action\n",
    "\treturn td_error, trace\n",
    "\n",
    "#Initialize\n",
    "n_features = env.observation_space.shape[0]\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "env.observation_space.high = np.array([0.5 if x == float(\"Inf\") else x for x in env.observation_space.high])\n",
    "env.observation_space.low = np.array([-0.5 if x == -float(\"Inf\") else x for x in env.observation_space.low])\n",
    "amp = env.observation_space.high - env.observation_space.low\n",
    "\n",
    "ig = igmn.IGMN(np.ones((n_features)), delta = 0.2, tau = 0.9)\n",
    "\n",
    "W = np.zeros((n_actions, K+1))\n",
    "W += initialQ #Q values initialization through bias\n",
    "total = 0\t#Total reward\n",
    "history = [] #Reward history (last 100)\n",
    "best = -np.inf #Best 100-episode average reward\n",
    "Q = np.zeros(n_actions)\n",
    "\n",
    "start_time = time.time()\n",
    "for i_episode in range(N_EPISODES):\t#For each episode\n",
    "\tstart_time = time.time()\n",
    "\tlr = 0.1 / (i_episode + 1)\n",
    "\tepsilon = 1 / math.sqrt(i_episode + 1)\n",
    "\teptotal = 0\t#Total reward for this episode\n",
    "\tobservation = env.reset()\n",
    "\tacts = np.zeros((K))\n",
    "\ttrace = addBias(acts)\t#Update traces\n",
    "\tfor t in range(MAX_STEPS):\t#For each step\n",
    "\t\t#ACT\n",
    "\t\tif i_episode == N_EPISODES-1:\n",
    "\t\t\tenv.render()\n",
    "\t\tacts = activate(observation, True, i_episode)\n",
    "\t\tif ig.size+1 > trace.shape[0]:\n",
    "\t\t\ttrace = np.concatenate((trace, [0.0]))\t\t\n",
    "\t\tinp = addBias(acts)\t#Add bias\n",
    "\t\ttrace = inp + decay * discount * trace #Update traces\n",
    "\t\toldQ = Q.copy()\n",
    "\t\tQ = W.dot(inp)\t#Feed forward to linear output layer\n",
    "\t\tif random.random() < epsilon:\t#Exploration\n",
    "\t\t\taction = env.action_space.sample()\n",
    "\t\telse:\t#Exploitation\n",
    "\t\t\taction = Q.argmax()\n",
    "\t\told_ob = observation.copy()\n",
    "\t\tend_time = time.time()\n",
    "\t\telapsed = end_time - start_time\n",
    "\t\tobservation, reward, done, info = env.step(action)\n",
    "\t\tstart_time = time.time()\n",
    "\t\t#LEARN\n",
    "\t\ttd_error, trace = learn(old_ob, action, observation, reward, done, trace, elapsed)\n",
    "\n",
    "\t\ttotal += reward\n",
    "\t\teptotal += reward\n",
    "\t\tif done or t == MAX_STEPS-1:\n",
    "\t\t\t#print(np.linalg.norm(m_err))\n",
    "\t\t\tif updateHistory(eptotal) or i_episode % 1 == 0:\n",
    "\t\t\t\tprint(\"Ep %d finished in %d steps. lr = %f, epsilon = %f, td error = %f, ep. reward = %f, #Comps: %d, BEST OF %d: %f\" % (i_episode, t+1, lr, epsilon, td_error, eptotal, ig.size, TRIALS, best))\n",
    "\t\t\t\tif REWARD_THRESHOLD != None and best >= REWARD_THRESHOLD:\n",
    "\t\t\t\t\tprint(\"SOLVED!\")\n",
    "\t\t\tbreak\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(\"Finished in %fs, Best of %d: %f\" % (elapsed_time, TRIALS, best))\n",
    "env.render(close=True)\n",
    "env.monitor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
